{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "As a reminder, the purpose of this project is to be able to predict whether a team will win given certain features. In addition, the project should also indicate which factors were most responsible in determining which team won the match. \n",
    "\n",
    "For the statistical section of this project, bootstrapping will be used to determine whether there is a difference between the selected features of the teams that won versus the teams that lost. The features to be analyzed are as follows: \n",
    "\n",
    "1. Gamelength\n",
    "2. Time of first tower taken\n",
    "3. Number of each type of dragon\n",
    "    - Earth\n",
    "    - Ocean\n",
    "    - Air\n",
    "    - Fire \n",
    "5. Mean gold of winning team by role\n",
    "    - Top\n",
    "    - Jungle\n",
    "    - Mid\n",
    "    - ADC \n",
    "    - Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "league = pd.read_csv(\"../Dataset/LeagueofLegends.csv\")\n",
    "\n",
    "nans = lambda df: df[df.isnull().any(axis=1)]\n",
    "nans(league) # Can't handle these kinds of NaN values, will instead drop \n",
    "league.dropna(inplace=True)\n",
    "league.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_wrangled = pd.read_csv(\"../Dataset/Wrangled_LeagueofLegends.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7582 entries, 0 to 7581\n",
      "Columns: 5720 entries, bResult to rbot_base\n",
      "dtypes: float64(43), int64(5677)\n",
      "memory usage: 330.9 MB\n"
     ]
    }
   ],
   "source": [
    "league_wrangled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7582 entries, 0 to 7581\n",
      "Data columns (total 57 columns):\n",
      "League              7582 non-null object\n",
      "Year                7582 non-null int64\n",
      "Season              7582 non-null object\n",
      "Type                7582 non-null object\n",
      "blueTeamTag         7582 non-null object\n",
      "bResult             7582 non-null int64\n",
      "rResult             7582 non-null int64\n",
      "redTeamTag          7582 non-null object\n",
      "gamelength          7582 non-null int64\n",
      "golddiff            7582 non-null object\n",
      "goldblue            7582 non-null object\n",
      "bKills              7582 non-null object\n",
      "bTowers             7582 non-null object\n",
      "bInhibs             7582 non-null object\n",
      "bDragons            7582 non-null object\n",
      "bBarons             7582 non-null object\n",
      "bHeralds            7582 non-null object\n",
      "goldred             7582 non-null object\n",
      "rKills              7582 non-null object\n",
      "rTowers             7582 non-null object\n",
      "rInhibs             7582 non-null object\n",
      "rDragons            7582 non-null object\n",
      "rBarons             7582 non-null object\n",
      "rHeralds            7582 non-null object\n",
      "blueTop             7582 non-null object\n",
      "blueTopChamp        7582 non-null object\n",
      "goldblueTop         7582 non-null object\n",
      "blueJungle          7582 non-null object\n",
      "blueJungleChamp     7582 non-null object\n",
      "goldblueJungle      7582 non-null object\n",
      "blueMiddle          7582 non-null object\n",
      "blueMiddleChamp     7582 non-null object\n",
      "goldblueMiddle      7582 non-null object\n",
      "blueADC             7582 non-null object\n",
      "blueADCChamp        7582 non-null object\n",
      "goldblueADC         7582 non-null object\n",
      "blueSupport         7582 non-null object\n",
      "blueSupportChamp    7582 non-null object\n",
      "goldblueSupport     7582 non-null object\n",
      "blueBans            7582 non-null object\n",
      "redTop              7582 non-null object\n",
      "redTopChamp         7582 non-null object\n",
      "goldredTop          7582 non-null object\n",
      "redJungle           7582 non-null object\n",
      "redJungleChamp      7582 non-null object\n",
      "goldredJungle       7582 non-null object\n",
      "redMiddle           7582 non-null object\n",
      "redMiddleChamp      7582 non-null object\n",
      "goldredMiddle       7582 non-null object\n",
      "redADC              7582 non-null object\n",
      "redADCChamp         7582 non-null object\n",
      "goldredADC          7582 non-null object\n",
      "redSupport          7582 non-null object\n",
      "redSupportChamp     7582 non-null object\n",
      "goldredSupport      7582 non-null object\n",
      "redBans             7582 non-null object\n",
      "Address             7582 non-null object\n",
      "dtypes: int64(4), object(53)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "league.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_p(blue, red, feature, N=10000): \n",
    "    bs_mean_diff = np.empty(N)\n",
    "    \n",
    "    mean_total   = np.mean(feature)\n",
    "    blue_shifted = blue - np.mean(blue) + mean_total\n",
    "    red_shifted  = red - np.mean(red) + mean_total \n",
    "    \n",
    "    for i in range(N): \n",
    "        bs_blue = np.random.choice(blue_shifted, size=len(league))\n",
    "        bs_red = np.random.choice(red_shifted, size=len(league))\n",
    "        bs_mean_diff[i] = np.mean(bs_blue) - np.mean(bs_red)\n",
    "        \n",
    "    emperical_mean_diff = np.mean(blue) - np.mean(red)\n",
    "    p = np.sum(bs_mean_diff >= emperical_mean_diff) / len(gamelength_mean_diff)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamelength\n",
    "\n",
    "Null hypothesis: There is no difference in average game legnth between games where the Red Team won versus games where the Blue                  Team won.\n",
    "\n",
    "Alternative hypothesis: There is a significant difference between the length of games where the Red Team won versus games where                         the Blue Team won. \n",
    "\n",
    "Testing this hypothesis will help determine if game length is a determining factor in which team is more likely to win. A possible scenario where this could be true is if the blue team is more likely to pick champions that outscale whereas the red team is more likely to pick champions that are stronger early in the game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "blue_win_gamelength = league.gamelength[league.bResult == 1]\n",
    "red_win_gamelength  = league.gamelength[league.bResult == 0]\n",
    "gamelength = league.gamelength\n",
    "\n",
    "p = calculate_p(blue_win_gamelength, \n",
    "                red_win_gamelength, \n",
    "                gamelength)\n",
    "\n",
    "print(f\"p-value: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time first tower taken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "\n",
    "def find_first_column(col_1, col_2, col_3): \n",
    "    if col_1 == 1:\n",
    "        tower_list = ast.literal_eval(col_2)\n",
    "        return tower_list[0][0]\n",
    "\n",
    "    else: \n",
    "        tower_list = ast.literal_eval(col_3)\n",
    "        return tower_list[0][0]\n",
    "\n",
    "    \n",
    "league['first_tower'] = league.apply(lambda x: find_first_column(x.bResult, x.bTowers, x.rTowers), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.4908\n"
     ]
    }
   ],
   "source": [
    "blue_first_tower = league.first_tower[league.bResult == 1]\n",
    "red_first_tower = league.first_tower[league.rResult == 0]\n",
    "first_tower = league.first_tower\n",
    "\n",
    "p = calculate_p(blue_first_tower,\n",
    "                red_first_tower, \n",
    "                first_tower)\n",
    "\n",
    "print(f\"p-value: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Each Type of Dragon\n",
    "    \n",
    "Null hypothesis: There is no difference in the number of each dragon taken when the Blue Team won versus when the Red Team won. \n",
    "\n",
    "Alternative hypothesis: A significant difference exists between the number of each dragon taken when the Blue Team wins versus                         when the Red Team wins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_winning_drag(col_1, col_2, col_3): \n",
    "    if col_1 == 1: \n",
    "        return col_2\n",
    "    else:\n",
    "        return col_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "league['winning_earth'] = league_wrangled.apply(lambda x: find_winning_drag(x.bResult, x.bEarth_drag, x.rEarth_drag), axis=1)\n",
    "league['winning_ocean'] = league_wrangled.apply(lambda x: find_winning_drag(x.bResult, x.bWater_drag, x.rWater_drag), axis=1)\n",
    "league['winning_air']   = league_wrangled.apply(lambda x: find_winning_drag(x.bResult, x.bAir_drag, x.rAir_drag), axis=1)\n",
    "league['winning_fire']  = league_wrangled.apply(lambda x: find_winning_drag(x.bResult, x.bFire_drag, x.rFire_drag), axis=1)\n",
    "league['winning_elder'] = league_wrangled.apply(lambda x: find_winning_drag(x.bResult, x.bElder_drag, x.rElder_drag), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.9999\n"
     ]
    }
   ],
   "source": [
    "blue_earth  = league.winning_earth[league.bResult == 1]\n",
    "red_earth   = league.winning_earth[league.bResult == 0]\n",
    "earth_drags = league.winning_earth\n",
    "\n",
    "p = calculate_p(blue_earth, \n",
    "                red_earth, \n",
    "                earth_drags)\n",
    "\n",
    "print(f\"p-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.9999\n"
     ]
    }
   ],
   "source": [
    "blue_ocean  = league.winning_ocean[league.bResult == 1]\n",
    "red_ocean   = league.winning_ocean[league.bResult == 0]\n",
    "ocean_drags = league.winning_ocean\n",
    "\n",
    "p = calculate_p(blue_ocean, \n",
    "                red_ocean, \n",
    "                ocean_drags)\n",
    "\n",
    "print(f\"p-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "blue_air  = league.winning_air[league.bResult == 1]\n",
    "red_air   = league.winning_air[league.bResult == 0]\n",
    "air_drags = league.winning_air\n",
    "\n",
    "p = calculate_p(blue_air, \n",
    "                red_air, \n",
    "                air_drags)\n",
    "\n",
    "print(f\"p-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "blue_fire  = league.winning_fire[league.bResult == 1]\n",
    "red_fire   = league.winning_fire[league.bResult == 0]\n",
    "fire_drags = league.winning_fire\n",
    "\n",
    "p = calculate_p(blue_fire, \n",
    "                red_fire, \n",
    "                fire_drags)\n",
    "\n",
    "print(f\"p-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "blue_elder  = league.winning_elder[league.bResult == 1]\n",
    "red_elder   = league.winning_elder[league.bResult == 0]\n",
    "elder_drags = league.winning_elder\n",
    "\n",
    "p = calculate_p(blue_elder, \n",
    "                red_elder, \n",
    "                elder_drags)\n",
    "\n",
    "print(f\"p-value: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Analysis on Infernal Dragons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInfernal Dragon statistics by winning team:\u001b[0m\n",
      "Blue sum: 1570.0\n",
      "Red sum:  516.0\n",
      "\n",
      "Blue mean: 0.38042161376302397\n",
      "Red mean:  0.14934876989869755\n",
      "\n",
      "Blue std: 0.6769413952055907\n",
      "Red std:  0.3979303851311427\n"
     ]
    }
   ],
   "source": [
    "blue_infernal = league.winning_fire[league.bResult == 1]\n",
    "red_infernal  = league.winning_fire[league.bResult == 0]\n",
    "print(\"\\033[1m\" + \"Infernal Dragon statistics by winning team:\" + \"\\033[0m\" )\n",
    "\n",
    "print(f\"Blue sum: {blue_infernal.sum()}\")\n",
    "print(f\"Red sum:  {red_infernal.sum()}\")\n",
    "print()\n",
    "print(f\"Blue mean: {blue_infernal.mean()}\")\n",
    "print(f\"Red mean:  {red_infernal.mean()}\")\n",
    "print()\n",
    "print(f\"Blue std: {blue_infernal.std()}\")\n",
    "print(f\"Red std:  {red_infernal.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Gold of Winning Team\n",
    "\n",
    "Null hypothesis: There is no difference between which role is most impactful based on who wins the game. \n",
    "\n",
    "Alternative hypothesis: One role is more likely to be more impactful depending on the side of the team. For example, perhaps                           the top laner recieved more gold throughout the game. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_winning_gold(col_1, col_2, col_3): \n",
    "    if col_1 == 1: \n",
    "        gold = ast.literal_eval(col_2)\n",
    "        return np.mean(gold)\n",
    "    else:\n",
    "        gold = ast.literal_eval(col_3)\n",
    "        return np.mean(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "league['top_gold']     = league.apply(lambda x: find_winning_gold(x.bResult, x.goldblueTop, x.goldredTop), axis=1)\n",
    "league['jungle_gold']  = league.apply(lambda x: find_winning_gold(x.bResult, x.goldblueJungle, x.goldredJungle), axis=1)\n",
    "league['mid_gold']     = league.apply(lambda x: find_winning_gold(x.bResult, x.goldblueMiddle, x.goldredMiddle), axis=1)\n",
    "league['adc_gold']     = league.apply(lambda x: find_winning_gold(x.bResult, x.goldblueADC, x.goldredADC), axis=1)\n",
    "league['support_gold'] = league.apply(lambda x: find_winning_gold(x.bResult, x.goldblueSupport, x.goldredSupport), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "blue_top_gold = league.top_gold[league.bResult == 1]\n",
    "red_top_gold  = league.top_gold[league.bResult == 0]\n",
    "top_gold      = league.top_gold\n",
    "\n",
    "p = calculate_p(blue_top_gold, \n",
    "                red_top_gold, \n",
    "                top_gold)\n",
    "\n",
    "print(f\"p-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "blue_jungle_gold = league.jungle_gold[league.bResult == 1]\n",
    "red_jungle_gold  = league.jungle_gold[league.bResult == 0]\n",
    "jungle_gold      = league.jungle_gold\n",
    "\n",
    "p = calculate_p(blue_jungle_gold, \n",
    "                red_jungle_gold, \n",
    "                jungle_gold)\n",
    "\n",
    "print(f\"p-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "blue_mid_gold = league.mid_gold[league.bResult == 1]\n",
    "red_mid_gold  = league.mid_gold[league.bResult == 0]\n",
    "mid_gold      = league.mid_gold\n",
    "\n",
    "p = calculate_p(blue_mid_gold, \n",
    "                red_mid_gold, \n",
    "                mid_gold)\n",
    "\n",
    "print(f\"p-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "blue_adc_gold = league.adc_gold[league.bResult == 1]\n",
    "red_adc_gold  = league.adc_gold[league.bResult == 0]\n",
    "adc_gold      = league.adc_gold\n",
    "\n",
    "p = calculate_p(blue_adc_gold, \n",
    "                red_adc_gold, \n",
    "                adc_gold)\n",
    "\n",
    "print(f\"p-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "blue_support_gold = league.support_gold[league.bResult == 1]\n",
    "red_support_gold  = league.support_gold[league.bResult == 0]\n",
    "support_gold      = league.support_gold\n",
    "\n",
    "p = calculate_p(blue_support_gold, \n",
    "                red_support_gold, \n",
    "                support_gold)\n",
    "\n",
    "print(f\"p-value: {p}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
